# Easy Transformer Speedy

The original Easy Transformer library is an implementation of transformers tailored for mechanistic interpretability. This library is an extension set up for greater training and inference speed, via parallelism and custom cuda kernels written in [Triton](https://github.com/openai/triton).

You probably shouldn't be using this for anything serious, since it's mostly just a learning tool for me to get more comfortable with optimizing large language model training. I'm also writing plenty of things from scratch that almost certainly have beter implementations elsewhere.





## Installation

`pip install git+https://github.com/anshradh/Easy-Transformer-Speedy`
